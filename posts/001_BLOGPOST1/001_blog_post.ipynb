{
 "cells": [
  {
   "cell_type": "raw",
   "id": "167058cc-3573-47be-9acf-e45486977caf",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Exploring GitHub and Jupyter Notebook\"\n",
    "description: \"This Blog is about my exploration with GitHub and JupyterLab for the first time, As well as what I have come to learn about LLMs\"\n",
    "author: \"Marco Firmender\"\n",
    "date: \"9/3/2025\"\n",
    "categories:\n",
    "  - JupyterLab\n",
    "  - GitHub\n",
    "  - LLMs\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b11d08-e4a6-4e49-87a1-129758efdf6e",
   "metadata": {},
   "source": [
    "# JupyterLab\n",
    "    At First, I thought that we were going to be using Jupyter Notebook, so I downloaded Jupyter Notebook from the App Store. This was not the case, and after I read Professor O'Donnell's Announcement, I was directed to the right software and how to access the right notebook. Now that I am working on the right notebook and interface, the tools and capabilities are very cool. I am also finding that Professor O'Donnell's guides to work through all the proper settings and configurations are extremely helpful and comprehensive. \n",
    "# GitHub\n",
    "    Github to me at first was very tedious, and I am still not 100% sure if this blog is going to upload correctly after I upload it to Github, Lol. what I know about GitHub from a brief online research is that GitHub is a cloud-based platform that allows developers *to store*, *manage*, and *collaborate on code*. GitHub is built on Git, a version control system created by Linus Torvalds. I am Excited to explore how we will use GitHub throughout the semester. \n",
    "# LLMs\n",
    "    LLMs are Large Language Models that are trained to understand and generate human-like language. They are called \"Large\" because they are trained on massive datasets, they have Billions and sometimes even Trillions of parameters. \n",
    "\n",
    "    What I have found particularly interesting, especially as it pertains to this class, is that these models are trained by reading huge amounts of text to learn patterns of language. Essentially, these models are predicting the next word in a sequence; the bigger the set, the more nuanced and refined it becomes, therefore making it more useful. \n",
    "\n",
    "    LLMs can:\n",
    "    - Generate text \n",
    "    - Answer questions\n",
    "    - Summarization (turn long documents into short overviews).\n",
    "    - Translation between languages\n",
    "    - Provide programming help (autocompleting or fixing code).\n",
    "    - Conversational AI (chatbots, personal assistants).\n",
    "    \n",
    "    However, Limitations of LLMs can include:\n",
    "    - LLMs Don’t understand in the human sense — they predict patterns, not truth.\n",
    "    - Can generate hallucinations (confident but wrong answers).\n",
    "    - Training requires massive computing power and energy.\n",
    "    - May carry biases from their training data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
